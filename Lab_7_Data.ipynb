{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import requests library to query the yahoo finance website and get the ticket symbol.\n",
    "Import fuzzywuzzy to get a partial match against yahoo's website.\n",
    "Import pandas_datareader to get the close date for each ticker symbol that we found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/fuzzywuzzy/fuzz.py:35: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import requests as rq\n",
    "import pandas as pd\n",
    "import fuzzywuzzy as fw\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "import pandas_datareader as pdr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the excel file from the Information is Beautiful website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_breach = pd.read_excel('Information is Beautiful- Data Breaches (public).xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop the first row which has the descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_breach = data_breach.drop(data_breach.index[[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bring in only the rows that I need from the spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_breach = data_breach[['Entity','YEAR','records lost','ORGANISATION','METHOD OF LEAK','DATA SENSITIVITY']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop any rows that have blank values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_breach = data_breach.dropna(how='any') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we'll replace the year values from 1-14 to the actual year. 14 is going to be 2017 because that is the most recent and not 2018 (which is the future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_breach['YEAR'] = data_breach['YEAR'].replace([0,1,2,3,4,5,6,7,8,9,10,11,12,13,14],[2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015,2016,2017,2017])\n",
    "#replace year values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the code needed to search our excel document with the yahoo API. Entities will take place of the squiggly brackets.\n",
    "The 'if statement' will see if the partial ratio is greater than 80 (means the spreadsheet Entity matches at least 80 percent of what's in yahoo finance) and if the exchange is NYSE or NASDAQ. If it is, then it will return the ticket symbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_symbol(entity):\n",
    "    url = \"http://d.yimg.com/autoc.finance.yahoo.com/autoc?query={}&region=1&lang=en\".format(entity)\n",
    "\n",
    "    result = rq.get(url).json()\n",
    "\n",
    "    for x in result['ResultSet']['Result']:\n",
    "        if fuzz.partial_ratio(entity, x['name']) >= 80:\n",
    "            if x['exchDisp'] == 'NYSE' or x['exchDisp'] == 'NASDAQ':\n",
    "                return x['symbol'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the Entity column as a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = data_breach['Entity'].tolist() #do if then statement to say if match > 90 then take name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an empty list which will be used to get the close dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickerList = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate through the get_symbol function for every entity in our spreadsheet. After you get the symbol then append it to the empty tickerList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for y in entities:\n",
    "    symbol = get_symbol(y)\n",
    "    tickerList.append(symbol)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not all symbols could be found through the Yahoo API. Error message said it couldn't read the URL, so I added a try-catch where if it errors out, then I'll print that the ticker wasn't found. \n",
    "Also I created an empty data frame with 3 columns and the for loop will iterate through and put all the data into the empty data frame, stockData."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ticker not found\n",
      "ticker not found\n"
     ]
    }
   ],
   "source": [
    "stockData = pd.DataFrame(columns = ['Symbol','Date', 'Close'])\n",
    "for x in tickerList:\n",
    "    if x is not None:\n",
    "        try:\n",
    "            result = pdr.get_data_yahoo(x)\n",
    "            result = result.reset_index()  \n",
    "            result['Symbol'] = x\n",
    "            result = result[['Symbol', 'Date', 'Close']]\n",
    "            stockData = stockData.append(result)\n",
    "        except:\n",
    "            print('ticker not found')\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert the ticker column into the end of the  original data_breach dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_breach.insert(loc = 6,column = 'ticker', value = tickerList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do a right join to merge the data breaches dataframe with the stockData dataframe. Match based on ticker column from data breach with Symbol from stockData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_data = pd.merge(data_breach, stockData, left_on='ticker',right_on='Symbol', how='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export the dataframe as a csv to upload to Tableau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_data.to_csv('Lab_7_Cleaned_Data2.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
